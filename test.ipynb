{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 04:14:22.470340: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sally/Desktop/Thesis_readings/Typological_Universal_BabyLM/env1/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data/wiki40b-txt/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_code = \"en\"\n",
    "r1 = \"_START_ARTICLE_\\n[^_]*\"\n",
    "r2 = \"_START_PARAGRAPH_\\n\"\n",
    "r3 = \"_START_SECTION_\\n[^_]*\"\n",
    "r4 = \"_NEWLINE_\"\n",
    "\n",
    "REGEX = re.compile(f\"({r1}|{r2}|{r3}|{r4})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating txt files from the Wiki-40b dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tf_dataset(ds, num_tokens, output_file):\n",
    "    # Turn to a numpy df so that we can easily extract text\n",
    "    # numpy_items = tfds.as_numpy(ds)\n",
    "    token_count = 0\n",
    "\n",
    "    with open(output_file, \"a\") as f:\n",
    "        for batch in ds.as_numpy_iterator():\n",
    "            # text is the feature we want to extract\n",
    "            for item in batch.get(\"text\"):\n",
    "                text = item.decode(\"UTF-8\")\n",
    "                text = re.sub(REGEX, \" \", text)\n",
    "                text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "                f.write(text)\n",
    "                f.write(\"\\n\")\n",
    "                token_count += len(text.split())\n",
    "                if num_tokens > 0 and token_count > num_tokens:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from validation split of the wiki-40b dataset, which has 163597 entries.\n",
    "# Don't run repeatedly once you loaded.\n",
    "ds = tfds.load(\n",
    "    f\"wiki40b/{lang_code}\",\n",
    "    split=\"train\",\n",
    "    shuffle_files=True,\n",
    "    data_dir=\"./data/\",\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 23:14:18.518598: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [128]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-18 23:14:18.519921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [128]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    }
   ],
   "source": [
    "# generating pure txt file for train split in wiki-40b\n",
    "process_tf_dataset(\n",
    "    ds, -1, \"./data/wiki40b-txt/\" + lang_code + \".train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't know why changing the split matters\n",
    "ds = tfds.load(\n",
    "    f\"wiki40b/{lang_code}\",\n",
    "    split=\"test\",\n",
    "    shuffle_files=True,\n",
    "    data_dir=\"./data/\",\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_tf_dataset(\n",
    "    ds, -1, \"./data/wiki40b-txt/\" + lang_code + \".test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load(\n",
    "    f\"wiki40b/{lang_code}\",\n",
    "    split=\"validation\",\n",
    "    shuffle_files=True,\n",
    "    data_dir=\"./data/\",\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_tf_dataset(\n",
    "    ds, -1, \"./data/wiki40b-txt/\" + lang_code + \".validation\"\n",
    ")\n",
    "# why this has so many entries?\n",
    "# 3 and 300 have same results, but -1 a lot more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.path.dirname(\"wiki40b-txt/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wiki40b-txt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ichij≈ç Fuyuyoshi (‰∏ÄÊù° ÂÜ¨ËâØ, July 29, 1465 ‚Äì April 21, 1514), son of regent Kaneyoshi, was a kugy≈ç or court noble of the Muromachi period (1336‚Äì1573) of Japan. He held a regent position kampaku two times from 1488 to 1493 and from 1497 to 1501. He adopted Fusamichi as son who was also his daughter's husband."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing training a BPETokenizer from scratch on different languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sally/Desktop/Thesis_readings/Typological_Universal_BabyLM/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "from tokenizers import AddedToken\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    \"en\": \"Hello, y'all! How are you üòÅ? (just testing the tokenizer)\",\n",
    "    \"ja\": \"„Åä„ÇÑ„Åô„Åø„Å™„Åï„ÅÑ\",\n",
    "    \"it\": \"Stiamo cercando una gioielleria.\",\n",
    "    \"ja_en\": \"„Åä„ÇÑ„Åô„Åø„Å™„Åï„ÅÑ\"\n",
    "             \"Hello, y'all! How are you üòÅ? (just testing the tokenizer)\",\n",
    "    \"it_en\": \"Stiamo cercando una gioielleria.\"\n",
    "             \"Hello, y'all! How are you üòÅ? (just testing the tokenizer)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tokenizer():\n",
    "\n",
    "    bpe_tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "    files = [f\"./data/wiki40b-txt/en.small\"]\n",
    "\n",
    "    bpe_tokenizer.train(files=files, vocab_size=32000, min_frequency=2)\n",
    "\n",
    "    tokenizer_path = f'./data/tokenizer/en'\n",
    "    if not os.path.exists(tokenizer_path):\n",
    "        os.makedirs(tokenizer_path)\n",
    "\n",
    "    # save the vocab.json and merges.txt files of the trained bpe tokenizer\n",
    "    bpe_tokenizer.save_model(tokenizer_path)\n",
    "\n",
    "    model_tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, tokenizer_type=\"gpt2\")\n",
    "    model_tokenizer.model_max_length = 512\n",
    "    model_tokenizer.add_special_tokens({\"pad_token\": AddedToken(\"<pad>\", normalized=True)})\n",
    "\n",
    "    print(f'Tokenizer vocab size: {len(model_tokenizer)}')\n",
    "    print(f'Tokenizer max sequence length: {model_tokenizer.model_max_length} \\n')\n",
    "\n",
    "    # save the full model tokenizer configuration files\n",
    "    model_tokenizer.save_pretrained(tokenizer_path)\n",
    "\n",
    "    output = model_tokenizer.encode_plus(sample[\"en\"])\n",
    "    print(output.tokens(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 32002\n",
      "Tokenizer max sequence length: 512 \n",
      "\n",
      "['H', 'ello', ',', 'ƒ†y', \"'\", 'all', '!', 'ƒ†How', 'ƒ†are', 'ƒ†you', 'ƒ†', '√∞', '≈Å', 'ƒ∫', 'ƒ£', '?', 'ƒ†(', 'just', 'ƒ†testing', 'ƒ†the', 'ƒ†to', 'ken', 'izer', ')'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Parsing with UDPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ufal.udpipe import Model, Pipeline, ProcessingError\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "from mosestokenizer import (\n",
    "    MosesPunctuationNormalizer,\n",
    "    MosesTokenizer,\n",
    "    MosesSentenceSplitter,\n",
    ")\n",
    "# from indicnlp.tokenize.sentence_tokenize import sentence_split as indic_sent_tokenize\n",
    "# from indicnlp.tokenize.indic_tokenize import trivial_tokenize as indic_word_tokenize\n",
    "# from hazm import sent_tokenize as persian_sent_tokenize\n",
    "# from hazm import word_tokenize as persian_word_tokenize\n",
    "# from hazm import Normalizer as PersianNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDPIPE_MODEL_LOOKUP = {\n",
    "    \"en\": \"udpipe_models/english-lines-ud-2.5-191206.udpipe\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--lang\", help=\"2-letter language code such as en, ru, vi, etc.\", default=\"en\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--udpipe_model_path\", help=\"path to UDPipe model file for this language\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_dir\",\n",
    "        help=\"path to data directory with original (normal-order) text\",\n",
    "        default=\"./data/wiki40b-txt/en_small.txt\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--parse_dir\",\n",
    "        help=\"path to directory where CONLLU parses of sentences should be stored\",\n",
    "        default=\"./parse\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--partitions\",\n",
    "        default=\"train,test,valid\",\n",
    "        help=\"comma-seprated list of partitions\",\n",
    "    )\n",
    "    parser.add_argument(\"--test_run\", action=\"store_true\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # create output directory if it doesn't yet exist\n",
    "    if not os.path.exists(args.parse_dir):\n",
    "        os.system(f\"mkdir -p {args.parse_dir}\")\n",
    "\n",
    "    # load UDPipe Model\n",
    "    sys.stderr.write(\"Loading model: \")\n",
    "    if args.udpipe_model_path is None:\n",
    "        model = Model.load(UDPIPE_MODEL_LOOKUP[args.lang])\n",
    "        sys.stderr.write(f\"{model}\\n\")\n",
    "    else:\n",
    "        model = Model.load(args.udpipe_model_path)\n",
    "    if not model:\n",
    "        sys.stderr.write(f\"Cannot load model from file '{args.udpipe_model_path}'\\n\")\n",
    "        sys.exit(1)\n",
    "    sys.stderr.write(\"done\\n\")\n",
    "\n",
    "    # create pipeline\n",
    "    pipeline = Pipeline(\n",
    "        model, \"horizontal\", Pipeline.DEFAULT, Pipeline.DEFAULT, \"conllu\"\n",
    "    )\n",
    "    err = ProcessingError()\n",
    "\n",
    "    # Make sentence tokenizer\n",
    "    if args.lang == \"hi\":\n",
    "        pass\n",
    "    elif args.lang == \"fa\":\n",
    "        persian_normalizer = PersianNormalizer()\n",
    "    else:\n",
    "        sent_tokenize = MosesSentenceSplitter(args.lang)\n",
    "        word_tokenize = MosesTokenizer(args.lang, no_escape=True)\n",
    "        normalize = MosesPunctuationNormalizer(args.lang)\n",
    "\n",
    "    # iterate over partitions\n",
    "    for partition in args.partitions.split(\",\"):\n",
    "        input_path = os.path.join(args.data_dir, f\"{args.lang}.{partition}\")\n",
    "        if args.test_run:\n",
    "            output_path = os.path.join(\n",
    "                args.parse_dir, f\"{args.lang}.{partition}.tiny.conllu\"\n",
    "            )\n",
    "        else:\n",
    "            output_path = os.path.join(\n",
    "                args.parse_dir, f\"{args.lang}.{partition}.conllu\"\n",
    "            )\n",
    "\n",
    "        with open(input_path) as f_in, open(output_path, \"w\") as f_out:\n",
    "\n",
    "            doc_counter = 0\n",
    "\n",
    "            # use iterator over lines in f_in to save memory\n",
    "            for document in f_in:\n",
    "\n",
    "                # Moses tokenizer will fail if the line is blank\n",
    "                if (len(document.strip())) == 0:\n",
    "                    sys.stderr.write(\"There was a blank line in the input file\\n\")\n",
    "                    continue\n",
    "\n",
    "                if args.lang == \"fa\":\n",
    "                    document = persian_normalizer.normalize(document)\n",
    "                    sentences = persian_sent_tokenize(document)\n",
    "                    sentences_tokenized = [persian_word_tokenize(s) for s in sentences]\n",
    "                elif args.lang == \"hi\":\n",
    "                    # split sentences\n",
    "                    sentences = indic_sent_tokenize(document, lang=\"hi\")\n",
    "                    # sentences_tokenized = [word_tokenize(normalize(s)) for s in sentences]\n",
    "                    sentences_tokenized = [indic_word_tokenize(s) for s in sentences]\n",
    "                else:\n",
    "                    # split sentences\n",
    "                    sentences = sent_tokenize([document])\n",
    "                    sentences_tokenized = [\n",
    "                        word_tokenize(normalize(s)) for s in sentences\n",
    "                    ]\n",
    "\n",
    "                sentences = [\" \".join(s) for s in sentences_tokenized]\n",
    "                sentences = \"\\n\".join(sentences)\n",
    "\n",
    "                # Process data\n",
    "                processed = pipeline.process(sentences, err)\n",
    "                if err.occurred():\n",
    "                    sys.stderr.write(\n",
    "                        f\"An error occurred in run_udpipe: {err.message}\\n\"\n",
    "                    )\n",
    "                    sys.exit(1)\n",
    "\n",
    "                f_out.write(processed)\n",
    "\n",
    "                doc_counter += 1\n",
    "\n",
    "                if args.test_run and doc_counter >= 5:\n",
    "                    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model: <Swig Object of type 'model *' at 0x112a9b8b0>\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load UDPipe Model\n",
    "sys.stderr.write(\"Loading model: \")\n",
    "udpipe_model_path = 0\n",
    "if udpipe_model_path == 0:\n",
    "    model = Model.load(UDPIPE_MODEL_LOOKUP[\"en\"])\n",
    "    sys.stderr.write(f\"{model}\\n\")\n",
    "else:\n",
    "    model = Model.load(udpipe_model_path)\n",
    "if not model:\n",
    "    sys.stderr.write(f\"Cannot load model from file '{udpipe_model_path}'\\n\")\n",
    "    sys.exit(1)\n",
    "sys.stderr.write(\"done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load(UDPIPE_MODEL_LOOKUP[\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.stderr.write(f\"{model}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"en\"\n",
    "partitions = \"train,test,valid\"\n",
    "parse_dir = \"./parse/\"\n",
    "test_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was a blank line in the input file\n"
     ]
    }
   ],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline(\n",
    "    model, \"horizontal\", Pipeline.DEFAULT, Pipeline.DEFAULT, \"conllu\"\n",
    ")\n",
    "err = ProcessingError()\n",
    "\n",
    "# Make sentence tokenizer\n",
    "sent_tokenize = MosesSentenceSplitter(lang)\n",
    "word_tokenize = MosesTokenizer(lang, no_escape=True)\n",
    "normalize = MosesPunctuationNormalizer(lang)\n",
    "\n",
    "# iterate over partitions\n",
    "for partition in partitions.split(\",\"):\n",
    "    input_path = os.path.join(\"./data/wiki40b-txt/\", f\"{lang}_{partition}.txt\")\n",
    "    if test_run:\n",
    "        output_path = os.path.join(\n",
    "            parse_dir, f\"{lang}_{partition}.tiny.conllu\"\n",
    "        )\n",
    "    else:\n",
    "        output_path = os.path.join(\n",
    "            parse_dir, f\"{lang}_{partition}.conllu\"\n",
    "        )\n",
    "\n",
    "    with open(input_path) as f_in, open(output_path, \"w\") as f_out:\n",
    "\n",
    "        doc_counter = 0\n",
    "\n",
    "        # use iterator over lines in f_in to save memory\n",
    "        for document in f_in:\n",
    "\n",
    "            # Moses tokenizer will fail if the line is blank\n",
    "            if (len(document.strip())) == 0:\n",
    "                sys.stderr.write(\"There was a blank line in the input file\\n\")\n",
    "                continue\n",
    "            # split sentences\n",
    "            sentences = sent_tokenize([document])\n",
    "            sentences_tokenized = [\n",
    "                word_tokenize(normalize(s)) for s in sentences\n",
    "            ]\n",
    "\n",
    "            sentences = [\" \".join(s) for s in sentences_tokenized]\n",
    "            sentences = \"\\n\".join(sentences)\n",
    "\n",
    "            # Process data\n",
    "            processed = pipeline.process(sentences, err)\n",
    "            if err.occurred():\n",
    "                sys.stderr.write(\n",
    "                    f\"An error occurred in run_udpipe: {err.message}\\n\"\n",
    "                )\n",
    "                sys.exit(1)\n",
    "\n",
    "            f_out.write(processed)\n",
    "\n",
    "            doc_counter += 1\n",
    "\n",
    "            if test_run and doc_counter >= 5:\n",
    "                exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of dependency graphs before and after reverse_content_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_content_head(sentence, validate=True):\n",
    "    \"\"\"Apply dependency parse convention change (deviation from vanilla UD)\n",
    "\n",
    "    Args:\n",
    "        sentence (List[Dict[str,int]]): a list of dictionaries, each corresponding to a word,\n",
    "        with the UD header names as dictionary keys\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str,int]]: same format as input\n",
    "    \"\"\"\n",
    "    CH_CONVERSION_ORDER = [\"cc\", \"case\", \"cop\", \"mark\"]\n",
    "    # find paths that should be reverted\n",
    "    for dep in CH_CONVERSION_ORDER:\n",
    "        for i in range(len(sentence)):\n",
    "            if sentence[i][\"dep\"] == dep or sentence[i][\"dep\"].startswith(dep + \":\"):\n",
    "                head = sentence[i][\"head\"] - 1\n",
    "                grandp = sentence[head][\"head\"] - 1\n",
    "                assert head > -1\n",
    "\n",
    "                # grandp -> head -> i\n",
    "                # grandp -> i -> head\n",
    "                sentence[i][\"head\"] = grandp + 1\n",
    "                sentence[head][\"head\"] = i + 1\n",
    "\n",
    "                sentence[i][\"dep\"] = sentence[head][\"dep\"]\n",
    "                sentence[head][\"dep\"] = \"lifted_\" + dep\n",
    "                assert sentence[i][\"index\"] == i + 1\n",
    "\n",
    "    # make sure none of the original dependency relations remain\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i][\"dep\"] in CH_CONVERSION_ORDER:\n",
    "            if validate:\n",
    "                sys.stderr.write(json.dumps(sentence))\n",
    "                sys.stderr.write(\"\\n\")\n",
    "            return None\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence = \"She eats lunch before she goes to the park.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters (excluding punctuation): 4\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "chinese_string = \"‰Ω†Â•ΩÔºå‰∏ñÁïåÔºÅ\"  # Replace with your Chinese string\n",
    "\n",
    "# Remove punctuation symbols using a regular expression\n",
    "chinese_string_without_punctuation = re.sub(r'[^\\w\\s]', '', chinese_string)\n",
    "\n",
    "# Calculate the number of characters in the cleaned string\n",
    "character_count = len(chinese_string_without_punctuation)\n",
    "\n",
    "print(\"Number of characters (excluding punctuation):\", character_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['Hello,', \"it's\", 'nice', 'to', 'meet', 'you!']\n"
     ]
    }
   ],
   "source": [
    "English_string = \"Hello, it's nice to meet you!\"\n",
    "character_count = len(English_string.split())\n",
    "print(character_count)\n",
    "print(English_string.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Counterfactual Grammars, switching verb and object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"\"\"\n",
    "1\tAs\tas\tADP\t_\t_\t3\tcase\t_\t_\n",
    "2\ta\ta\tDET\tIND-SG\tDefinite=Ind|PronType=Art\t3\tdet\t_\t_\n",
    "3\tyouth\tyouth\tNOUN\tSG-NOM\tNumber=Sing\t5\tobl\t_\t_\n",
    "4\the\the\tPRON\tPERS-P3SG-NOM\tCase=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs\t5\tnsubj\t_\t_\n",
    "5\tfollowed\tfollow\tVERB\tPAST\tMood=Ind|Tense=Past|VerbForm=Fin\t0\troot\t_\t_\n",
    "6\ta\ta\tDET\tIND-SG\tDefinite=Ind|PronType=Art\t8\tdet\t_\t_\n",
    "7\treligious\treligious\tADJ\tPOS\tDegree=Pos\t8\tamod\t_\t_\n",
    "8\tpilgrimage\tpilgrimage\tNOUN\tSG-NOM\tNumber=Sing\t5\tobj\t_\t_\n",
    "9\tthat\tthat\tPRON\tREL\tPronType=Rel\t10\tnsubj\t_\t_\n",
    "10\ttook\ttake\tVERB\tPAST\tMood=Ind|Tense=Past|VerbForm=Fin\t8\tacl:relcl\t_\t_\n",
    "11\thim\the\tPRON\tPERS-P3SG-ACC\tCase=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs\t10\tobj\t_\t_\n",
    "12\tto\tto\tADP\t_\t_\t13\tcase\t_\t_\n",
    "13\tTransylvania\tTransylvania\tPROPN\tSG-NOM\tNumber=Sing\t10\tobl\t_\t_\n",
    "14\tCollege\tCollege\tPROPN\tSG-NOM\tNumber=Sing\t13\tflat\t_\t_\n",
    "15\t,\t,\tPUNCT\tComma\t_\t5\tpunct\t_\t_\n",
    "16\ta\ta\tDET\tIND-SG\tDefinite=Ind|PronType=Art\t17\tdet\t_\t_\n",
    "17\tDisciples\tDisciple\tNOUN\tSG-NOM\tNumber=Sing\t5\tobj\t_\t_\n",
    "18\tof\tof\tADP\t_\t_\t20\tcase\t_\t_\n",
    "19\tChrist\tChrist\tADJ\tSPL\tDegree=Sup\t20\tamod\t_\t_\n",
    "20\tschool\tschool\tNOUN\tSG-NOM\tNumber=Sing\t17\tnmod\t_\t_\n",
    "21\tin\tin\tADP\t_\t_\t22\tcase\t_\t_\n",
    "22\tLexington\tLexington\tPROPN\tSG-NOM\tNumber=Sing\t20\tnmod\t_\t_\n",
    "23\t,\t,\tPUNCT\tComma\t_\t22\tpunct\t_\t_\n",
    "24\tKentucky\tKentucky\tPROPN\tSG-NOM\tNumber=Sing\t22\tconj\t_\t_\n",
    "25\t.\t.\tPUNCT\tPeriod\t_\t5\tpunct\t_\t_\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = list(map(lambda x: x.split(\"\\t\"), x.split(\"\\n\")))\n",
    "sentence = split[1:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', 'As', 'as', 'ADP', '_', '_', '3', 'case', '_', '_']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Arthur Ford was born in Titusville, Florida and grew up in Fort Pierce, Florida\" \n",
    "\"Arthur Ford was in Titusville, Florida born and in Fort Pierce, Florida grew up\"\n",
    "\"Arthur Ford was born Titusville, FLorida in and grew up Fort Pierce, Forida in\"\n",
    "\"As a youth he followed a religious pilgrimage that took him to Transylvania College, a Disciples of Christ school in Lexington, Kentucky.\"\n",
    "\"As a youth he a religious pilgrimage that him to Transylvania College, a Disciples of Christ school in Lexington, Kentucky took followed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER = [\n",
    "    \"index\",\n",
    "    \"word\",\n",
    "    \"lemma\",\n",
    "    \"posUni\",\n",
    "    \"posFine\",\n",
    "    \"morph\",\n",
    "    \"head\",\n",
    "    \"dep\",\n",
    "    \"_\",\n",
    "    \"_\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(sentence)):\n",
    "    if sentence[i][0].startswith(\"#\"):\n",
    "        if sentence[i][0].startswith(\"# newdoc\"):\n",
    "            newdoc = True\n",
    "        continue\n",
    "    if \"-\" in sentence[i][0]:  # if it is NUM-NUM\n",
    "        continue\n",
    "    if \".\" in sentence[i][0]:\n",
    "        continue\n",
    "\n",
    "    # sentence = list of dicts, where each key is a field name (see HEADER)\n",
    "    sentence[i] = dict([(y, sentence[i][x]) for x, y in enumerate(HEADER)])\n",
    "    sentence[i][\"head\"] = int(sentence[i][\"head\"])\n",
    "    sentence[i][\"index\"] = int(sentence[i][\"index\"])\n",
    "    sentence[i][\"word\"] = sentence[i][\"word\"].lower()\n",
    "\n",
    "    # if self.storeMorph:\n",
    "    #     sentence[i][\"morph\"] = sentence[i][\"morph\"].split(\"|\")\n",
    "\n",
    "    sentence[i][\"dep\"] = sentence[i][\"dep\"].lower()\n",
    "    result.append(sentence[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 1,\n",
       "  'word': 'as',\n",
       "  'lemma': 'as',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 3,\n",
       "  'dep': 'case',\n",
       "  '_': '_'},\n",
       " {'index': 2,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 3,\n",
       "  'dep': 'det',\n",
       "  '_': '_'},\n",
       " {'index': 3,\n",
       "  'word': 'youth',\n",
       "  'lemma': 'youth',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'dep': 'obl',\n",
       "  '_': '_'},\n",
       " {'index': 4,\n",
       "  'word': 'he',\n",
       "  'lemma': 'he',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'PERS-P3SG-NOM',\n",
       "  'morph': 'Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 5,\n",
       "  'dep': 'nsubj',\n",
       "  '_': '_'},\n",
       " {'index': 5,\n",
       "  'word': 'followed',\n",
       "  'lemma': 'follow',\n",
       "  'posUni': 'VERB',\n",
       "  'posFine': 'PAST',\n",
       "  'morph': 'Mood=Ind|Tense=Past|VerbForm=Fin',\n",
       "  'head': 0,\n",
       "  'dep': 'root',\n",
       "  '_': '_'},\n",
       " {'index': 6,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 8,\n",
       "  'dep': 'det',\n",
       "  '_': '_'},\n",
       " {'index': 7,\n",
       "  'word': 'religious',\n",
       "  'lemma': 'religious',\n",
       "  'posUni': 'ADJ',\n",
       "  'posFine': 'POS',\n",
       "  'morph': 'Degree=Pos',\n",
       "  'head': 8,\n",
       "  'dep': 'amod',\n",
       "  '_': '_'},\n",
       " {'index': 8,\n",
       "  'word': 'pilgrimage',\n",
       "  'lemma': 'pilgrimage',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'dep': 'obj',\n",
       "  '_': '_'},\n",
       " {'index': 9,\n",
       "  'word': 'that',\n",
       "  'lemma': 'that',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'REL',\n",
       "  'morph': 'PronType=Rel',\n",
       "  'head': 10,\n",
       "  'dep': 'nsubj',\n",
       "  '_': '_'},\n",
       " {'index': 10,\n",
       "  'word': 'took',\n",
       "  'lemma': 'take',\n",
       "  'posUni': 'VERB',\n",
       "  'posFine': 'PAST',\n",
       "  'morph': 'Mood=Ind|Tense=Past|VerbForm=Fin',\n",
       "  'head': 8,\n",
       "  'dep': 'acl:relcl',\n",
       "  '_': '_'},\n",
       " {'index': 11,\n",
       "  'word': 'him',\n",
       "  'lemma': 'he',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'PERS-P3SG-ACC',\n",
       "  'morph': 'Case=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 10,\n",
       "  'dep': 'obj',\n",
       "  '_': '_'},\n",
       " {'index': 12,\n",
       "  'word': 'to',\n",
       "  'lemma': 'to',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 13,\n",
       "  'dep': 'case',\n",
       "  '_': '_'},\n",
       " {'index': 13,\n",
       "  'word': 'transylvania',\n",
       "  'lemma': 'Transylvania',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 10,\n",
       "  'dep': 'obl',\n",
       "  '_': '_'},\n",
       " {'index': 14,\n",
       "  'word': 'college',\n",
       "  'lemma': 'College',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 13,\n",
       "  'dep': 'flat',\n",
       "  '_': '_'},\n",
       " {'index': 15,\n",
       "  'word': ',',\n",
       "  'lemma': ',',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Comma',\n",
       "  'morph': '_',\n",
       "  'head': 5,\n",
       "  'dep': 'punct',\n",
       "  '_': '_'},\n",
       " {'index': 16,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 17,\n",
       "  'dep': 'det',\n",
       "  '_': '_'},\n",
       " {'index': 17,\n",
       "  'word': 'disciples',\n",
       "  'lemma': 'Disciple',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'dep': 'obj',\n",
       "  '_': '_'},\n",
       " {'index': 18,\n",
       "  'word': 'of',\n",
       "  'lemma': 'of',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 20,\n",
       "  'dep': 'case',\n",
       "  '_': '_'},\n",
       " {'index': 19,\n",
       "  'word': 'christ',\n",
       "  'lemma': 'Christ',\n",
       "  'posUni': 'ADJ',\n",
       "  'posFine': 'SPL',\n",
       "  'morph': 'Degree=Sup',\n",
       "  'head': 20,\n",
       "  'dep': 'amod',\n",
       "  '_': '_'},\n",
       " {'index': 20,\n",
       "  'word': 'school',\n",
       "  'lemma': 'school',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 17,\n",
       "  'dep': 'nmod',\n",
       "  '_': '_'},\n",
       " {'index': 21,\n",
       "  'word': 'in',\n",
       "  'lemma': 'in',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 22,\n",
       "  'dep': 'case',\n",
       "  '_': '_'},\n",
       " {'index': 22,\n",
       "  'word': 'lexington',\n",
       "  'lemma': 'Lexington',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 20,\n",
       "  'dep': 'nmod',\n",
       "  '_': '_'},\n",
       " {'index': 23,\n",
       "  'word': ',',\n",
       "  'lemma': ',',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Comma',\n",
       "  'morph': '_',\n",
       "  'head': 22,\n",
       "  'dep': 'punct',\n",
       "  '_': '_'},\n",
       " {'index': 24,\n",
       "  'word': 'kentucky',\n",
       "  'lemma': 'Kentucky',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 22,\n",
       "  'dep': 'conj',\n",
       "  '_': '_'},\n",
       " {'index': 25,\n",
       "  'word': '.',\n",
       "  'lemma': '.',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Period',\n",
       "  'morph': '_',\n",
       "  'head': 5,\n",
       "  'dep': 'punct',\n",
       "  '_': '_'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_content_head(sentence, validate=True):\n",
    "    \"\"\"Apply dependency parse convention change (deviation from vanilla UD)\n",
    "\n",
    "    Args:\n",
    "        sentence (List[Dict[str,int]]): a list of dictionaries, each corresponding to a word,\n",
    "        with the UD header names as dictionary keys\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str,int]]: same format as input\n",
    "    \"\"\"\n",
    "    CH_CONVERSION_ORDER = [\"cc\", \"case\", \"cop\", \"mark\"]\n",
    "    # find paths that should be reverted\n",
    "    for dep in CH_CONVERSION_ORDER:\n",
    "        for i in range(len(sentence)):\n",
    "            if sentence[i][\"dep\"] == dep or sentence[i][\"dep\"].startswith(dep + \":\"):\n",
    "                head = sentence[i][\"head\"] - 1\n",
    "                grandp = sentence[head][\"head\"] - 1\n",
    "                assert head > -1\n",
    "\n",
    "                # grandp -> head -> i\n",
    "                # grandp -> i -> head\n",
    "                sentence[i][\"head\"] = grandp + 1\n",
    "                sentence[head][\"head\"] = i + 1\n",
    "\n",
    "                sentence[i][\"dep\"] = sentence[head][\"dep\"]\n",
    "                sentence[head][\"dep\"] = \"lifted_\" + dep\n",
    "                assert sentence[i][\"index\"] == i + 1\n",
    "\n",
    "    # make sure none of the original dependency relations remain\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i][\"dep\"] in CH_CONVERSION_ORDER:\n",
    "            if validate:\n",
    "                sys.stderr.write(json.dumps(sentence))\n",
    "                sys.stderr.write(\"\\n\")\n",
    "            return None\n",
    "\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = reverse_content_head(result, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 1,\n",
       "  'word': 'as',\n",
       "  'lemma': 'as',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 5,\n",
       "  'dep': 'obl',\n",
       "  '_': '_'},\n",
       " {'index': 2,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 3,\n",
       "  'dep': 'det',\n",
       "  '_': '_'},\n",
       " {'index': 3,\n",
       "  'word': 'youth',\n",
       "  'lemma': 'youth',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 1,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_'},\n",
       " {'index': 4,\n",
       "  'word': 'he',\n",
       "  'lemma': 'he',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'PERS-P3SG-NOM',\n",
       "  'morph': 'Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 5,\n",
       "  'dep': 'nsubj',\n",
       "  '_': '_'},\n",
       " {'index': 5,\n",
       "  'word': 'followed',\n",
       "  'lemma': 'follow',\n",
       "  'posUni': 'VERB',\n",
       "  'posFine': 'PAST',\n",
       "  'morph': 'Mood=Ind|Tense=Past|VerbForm=Fin',\n",
       "  'head': 0,\n",
       "  'dep': 'root',\n",
       "  '_': '_'},\n",
       " {'index': 6,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 8,\n",
       "  'dep': 'det',\n",
       "  '_': '_'},\n",
       " {'index': 7,\n",
       "  'word': 'religious',\n",
       "  'lemma': 'religious',\n",
       "  'posUni': 'ADJ',\n",
       "  'posFine': 'POS',\n",
       "  'morph': 'Degree=Pos',\n",
       "  'head': 8,\n",
       "  'dep': 'amod',\n",
       "  '_': '_'},\n",
       " {'index': 8,\n",
       "  'word': 'pilgrimage',\n",
       "  'lemma': 'pilgrimage',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'dep': 'obj',\n",
       "  '_': '_'},\n",
       " {'index': 9,\n",
       "  'word': 'that',\n",
       "  'lemma': 'that',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'REL',\n",
       "  'morph': 'PronType=Rel',\n",
       "  'head': 10,\n",
       "  'dep': 'nsubj',\n",
       "  '_': '_'},\n",
       " {'index': 10,\n",
       "  'word': 'took',\n",
       "  'lemma': 'take',\n",
       "  'posUni': 'VERB',\n",
       "  'posFine': 'PAST',\n",
       "  'morph': 'Mood=Ind|Tense=Past|VerbForm=Fin',\n",
       "  'head': 8,\n",
       "  'dep': 'acl:relcl',\n",
       "  '_': '_'},\n",
       " {'index': 11,\n",
       "  'word': 'him',\n",
       "  'lemma': 'he',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'PERS-P3SG-ACC',\n",
       "  'morph': 'Case=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 10,\n",
       "  'dep': 'obj',\n",
       "  '_': '_'},\n",
       " {'index': 12,\n",
       "  'word': 'to',\n",
       "  'lemma': 'to',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 10,\n",
       "  'dep': 'obl',\n",
       "  '_': '_'},\n",
       " {'index': 13,\n",
       "  'word': 'transylvania',\n",
       "  'lemma': 'Transylvania',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 12,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_'},\n",
       " {'index': 14,\n",
       "  'word': 'college',\n",
       "  'lemma': 'College',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 13,\n",
       "  'dep': 'flat',\n",
       "  '_': '_'},\n",
       " {'index': 15,\n",
       "  'word': ',',\n",
       "  'lemma': ',',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Comma',\n",
       "  'morph': '_',\n",
       "  'head': 5,\n",
       "  'dep': 'punct',\n",
       "  '_': '_'},\n",
       " {'index': 16,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 17,\n",
       "  'dep': 'det',\n",
       "  '_': '_'},\n",
       " {'index': 17,\n",
       "  'word': 'disciples',\n",
       "  'lemma': 'Disciple',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'dep': 'obj',\n",
       "  '_': '_'},\n",
       " {'index': 18,\n",
       "  'word': 'of',\n",
       "  'lemma': 'of',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 17,\n",
       "  'dep': 'nmod',\n",
       "  '_': '_'},\n",
       " {'index': 19,\n",
       "  'word': 'christ',\n",
       "  'lemma': 'Christ',\n",
       "  'posUni': 'ADJ',\n",
       "  'posFine': 'SPL',\n",
       "  'morph': 'Degree=Sup',\n",
       "  'head': 20,\n",
       "  'dep': 'amod',\n",
       "  '_': '_'},\n",
       " {'index': 20,\n",
       "  'word': 'school',\n",
       "  'lemma': 'school',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 18,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_'},\n",
       " {'index': 21,\n",
       "  'word': 'in',\n",
       "  'lemma': 'in',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 20,\n",
       "  'dep': 'nmod',\n",
       "  '_': '_'},\n",
       " {'index': 22,\n",
       "  'word': 'lexington',\n",
       "  'lemma': 'Lexington',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 21,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_'},\n",
       " {'index': 23,\n",
       "  'word': ',',\n",
       "  'lemma': ',',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Comma',\n",
       "  'morph': '_',\n",
       "  'head': 22,\n",
       "  'dep': 'punct',\n",
       "  '_': '_'},\n",
       " {'index': 24,\n",
       "  'word': 'kentucky',\n",
       "  'lemma': 'Kentucky',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 22,\n",
       "  'dep': 'conj',\n",
       "  '_': '_'},\n",
       " {'index': 25,\n",
       "  'word': '.',\n",
       "  'lemma': '.',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Period',\n",
       "  'morph': '_',\n",
       "  'head': 5,\n",
       "  'dep': 'punct',\n",
       "  '_': '_'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 1,\n",
       "  'word': 'as',\n",
       "  'lemma': 'as',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 5,\n",
       "  'dep': 'obl',\n",
       "  '_': '_'},\n",
       " {'index': 2,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 3,\n",
       "  'dep': 'det',\n",
       "  '_': '_'},\n",
       " {'index': 3,\n",
       "  'word': 'youth',\n",
       "  'lemma': 'youth',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 1,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_'},\n",
       " {'index': 4,\n",
       "  'word': 'he',\n",
       "  'lemma': 'he',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'PERS-P3SG-NOM',\n",
       "  'morph': 'Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 5,\n",
       "  'dep': 'nsubj',\n",
       "  '_': '_'},\n",
       " {'index': 5,\n",
       "  'word': 'followed',\n",
       "  'lemma': 'follow',\n",
       "  'posUni': 'VERB',\n",
       "  'posFine': 'PAST',\n",
       "  'morph': 'Mood=Ind|Tense=Past|VerbForm=Fin',\n",
       "  'head': 0,\n",
       "  'dep': 'root',\n",
       "  '_': '_'},\n",
       " {'index': 6,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 8,\n",
       "  'dep': 'det',\n",
       "  '_': '_'},\n",
       " {'index': 7,\n",
       "  'word': 'religious',\n",
       "  'lemma': 'religious',\n",
       "  'posUni': 'ADJ',\n",
       "  'posFine': 'POS',\n",
       "  'morph': 'Degree=Pos',\n",
       "  'head': 8,\n",
       "  'dep': 'amod',\n",
       "  '_': '_'},\n",
       " {'index': 8,\n",
       "  'word': 'pilgrimage',\n",
       "  'lemma': 'pilgrimage',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'dep': 'obj',\n",
       "  '_': '_'},\n",
       " {'index': 9,\n",
       "  'word': 'that',\n",
       "  'lemma': 'that',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'REL',\n",
       "  'morph': 'PronType=Rel',\n",
       "  'head': 10,\n",
       "  'dep': 'nsubj',\n",
       "  '_': '_'},\n",
       " {'index': 10,\n",
       "  'word': 'took',\n",
       "  'lemma': 'take',\n",
       "  'posUni': 'VERB',\n",
       "  'posFine': 'PAST',\n",
       "  'morph': 'Mood=Ind|Tense=Past|VerbForm=Fin',\n",
       "  'head': 8,\n",
       "  'dep': 'acl:relcl',\n",
       "  '_': '_'},\n",
       " {'index': 11,\n",
       "  'word': 'him',\n",
       "  'lemma': 'he',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'PERS-P3SG-ACC',\n",
       "  'morph': 'Case=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 10,\n",
       "  'dep': 'obj',\n",
       "  '_': '_'},\n",
       " {'index': 12,\n",
       "  'word': 'to',\n",
       "  'lemma': 'to',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 10,\n",
       "  'dep': 'obl',\n",
       "  '_': '_'},\n",
       " {'index': 13,\n",
       "  'word': 'transylvania',\n",
       "  'lemma': 'Transylvania',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 12,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_'},\n",
       " {'index': 14,\n",
       "  'word': 'college',\n",
       "  'lemma': 'College',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 13,\n",
       "  'dep': 'flat',\n",
       "  '_': '_'},\n",
       " {'index': 15,\n",
       "  'word': ',',\n",
       "  'lemma': ',',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Comma',\n",
       "  'morph': '_',\n",
       "  'head': 5,\n",
       "  'dep': 'punct',\n",
       "  '_': '_'},\n",
       " {'index': 16,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 17,\n",
       "  'dep': 'det',\n",
       "  '_': '_'},\n",
       " {'index': 17,\n",
       "  'word': 'disciples',\n",
       "  'lemma': 'Disciple',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'dep': 'obj',\n",
       "  '_': '_'},\n",
       " {'index': 18,\n",
       "  'word': 'of',\n",
       "  'lemma': 'of',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 17,\n",
       "  'dep': 'nmod',\n",
       "  '_': '_'},\n",
       " {'index': 19,\n",
       "  'word': 'christ',\n",
       "  'lemma': 'Christ',\n",
       "  'posUni': 'ADJ',\n",
       "  'posFine': 'SPL',\n",
       "  'morph': 'Degree=Sup',\n",
       "  'head': 20,\n",
       "  'dep': 'amod',\n",
       "  '_': '_'},\n",
       " {'index': 20,\n",
       "  'word': 'school',\n",
       "  'lemma': 'school',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 18,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_'},\n",
       " {'index': 21,\n",
       "  'word': 'in',\n",
       "  'lemma': 'in',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 20,\n",
       "  'dep': 'nmod',\n",
       "  '_': '_'},\n",
       " {'index': 22,\n",
       "  'word': 'lexington',\n",
       "  'lemma': 'Lexington',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 21,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_'},\n",
       " {'index': 23,\n",
       "  'word': ',',\n",
       "  'lemma': ',',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Comma',\n",
       "  'morph': '_',\n",
       "  'head': 22,\n",
       "  'dep': 'punct',\n",
       "  '_': '_'},\n",
       " {'index': 24,\n",
       "  'word': 'kentucky',\n",
       "  'lemma': 'Kentucky',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 22,\n",
       "  'dep': 'conj',\n",
       "  '_': '_'},\n",
       " {'index': 25,\n",
       "  'word': '.',\n",
       "  'lemma': '.',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Period',\n",
       "  'morph': '_',\n",
       "  'head': 5,\n",
       "  'dep': 'punct',\n",
       "  '_': '_'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Stanza instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stanza\n",
    "import stanza\n",
    "\n",
    "# Load the English pipeline\n",
    "stanza.download('en')  # Download the English model\n",
    "nlp = stanza.Pipeline('en')  # Initialize the English pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline('en', processors='tokenize,lemma,pos,depparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanza.utils.conll import CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Bill seems honest. Bill is honest. \\n I believe so.\")\n",
    "# dict = doc.sentences[2].to_dict()\n",
    "# dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of list of dictionaries\n",
    "dicts = doc.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'text': 'Bill',\n",
       "  'lemma': 'Bill',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 2,\n",
       "  'deprel': 'nsubj',\n",
       "  'start_char': 0,\n",
       "  'end_char': 4},\n",
       " {'id': 2,\n",
       "  'text': 'seems',\n",
       "  'lemma': 'seem',\n",
       "  'upos': 'VERB',\n",
       "  'xpos': 'VBZ',\n",
       "  'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin',\n",
       "  'head': 0,\n",
       "  'deprel': 'root',\n",
       "  'start_char': 5,\n",
       "  'end_char': 10},\n",
       " {'id': 3,\n",
       "  'text': 'honest',\n",
       "  'lemma': 'honest',\n",
       "  'upos': 'ADJ',\n",
       "  'xpos': 'JJ',\n",
       "  'feats': 'Degree=Pos',\n",
       "  'head': 2,\n",
       "  'deprel': 'xcomp',\n",
       "  'start_char': 11,\n",
       "  'end_char': 17},\n",
       " {'id': 4,\n",
       "  'text': '.',\n",
       "  'lemma': '.',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': '.',\n",
       "  'head': 2,\n",
       "  'deprel': 'punct',\n",
       "  'start_char': 17,\n",
       "  'end_char': 18}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r9/wg8zpnrn019c1n4037r38txc0000gn/T/ipykernel_88229/4275877336.py:1: UserWarning: doc2conll is deprecated.  Please use \"{:C}\".format(doc) and use the text format directly\n",
      "  CoNLL.doc2conll(doc)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['# text = Bill seems honest.',\n",
       "  '# sent_id = 0',\n",
       "  '1\\tBill\\tBill\\tPROPN\\tNNP\\tNumber=Sing\\t2\\tnsubj\\t_\\tstart_char=0|end_char=4',\n",
       "  '2\\tseems\\tseem\\tVERB\\tVBZ\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t0\\troot\\t_\\tstart_char=5|end_char=10',\n",
       "  '3\\thonest\\thonest\\tADJ\\tJJ\\tDegree=Pos\\t2\\txcomp\\t_\\tstart_char=11|end_char=17',\n",
       "  '4\\t.\\t.\\tPUNCT\\t.\\t_\\t2\\tpunct\\t_\\tstart_char=17|end_char=18'],\n",
       " ['# text = Bill is honest.',\n",
       "  '# sent_id = 1',\n",
       "  '1\\tBill\\tBill\\tPROPN\\tNNP\\tNumber=Sing\\t3\\tnsubj\\t_\\tstart_char=19|end_char=23',\n",
       "  '2\\tis\\tbe\\tAUX\\tVBZ\\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\\t3\\tcop\\t_\\tstart_char=24|end_char=26',\n",
       "  '3\\thonest\\thonest\\tADJ\\tJJ\\tDegree=Pos\\t0\\troot\\t_\\tstart_char=27|end_char=33',\n",
       "  '4\\t.\\t.\\tPUNCT\\t.\\t_\\t3\\tpunct\\t_\\tstart_char=33|end_char=34'],\n",
       " ['# text = I believe so.',\n",
       "  '# sent_id = 2',\n",
       "  '1\\tI\\tI\\tPRON\\tPRP\\tCase=Nom|Number=Sing|Person=1|PronType=Prs\\t2\\tnsubj\\t_\\tstart_char=37|end_char=38',\n",
       "  '2\\tbelieve\\tbelieve\\tVERB\\tVBP\\tMood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\\t0\\troot\\t_\\tstart_char=39|end_char=46',\n",
       "  '3\\tso\\tso\\tADV\\tRB\\t_\\t2\\tadvmod\\t_\\tstart_char=47|end_char=49',\n",
       "  '4\\t.\\t.\\tPUNCT\\t.\\t_\\t2\\tpunct\\t_\\tstart_char=49|end_char=50']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CoNLL.doc2conll(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoNLL.write_doc2conll(doc, 'lala.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I'd like to work with you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoNLL.write_doc2conll(doc, 'lala.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = CoNLL.conll2doc('lala.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'text': 'Bill',\n",
       "  'lemma': 'Bill',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 2,\n",
       "  'deprel': 'nsubj',\n",
       "  'start_char': 0,\n",
       "  'end_char': 4,\n",
       "  'ner': 'S-PERSON',\n",
       "  'multi_ner': ('S-PERSON',)},\n",
       " {'id': 2,\n",
       "  'text': 'seems',\n",
       "  'lemma': 'seem',\n",
       "  'upos': 'VERB',\n",
       "  'xpos': 'VBZ',\n",
       "  'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin',\n",
       "  'head': 0,\n",
       "  'deprel': 'root',\n",
       "  'start_char': 5,\n",
       "  'end_char': 10,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 3,\n",
       "  'text': 'honest',\n",
       "  'lemma': 'honest',\n",
       "  'upos': 'ADJ',\n",
       "  'xpos': 'JJ',\n",
       "  'feats': 'Degree=Pos',\n",
       "  'head': 2,\n",
       "  'deprel': 'xcomp',\n",
       "  'start_char': 11,\n",
       "  'end_char': 17,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll_u_parse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sally/Desktop/Thesis_readings/Typological_Universal_BabyLM/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('zh', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conllu_file(path):\n",
    "    \"\"\"Reads all data from a CoNNL-U format file and returns a list of \n",
    "    strings, each corresponding to a sentence in the dataset. Assumes \n",
    "    properly formed CoNNL-U format data.\n",
    "    NOTE: this function is deprecated and we instead use an iterator\n",
    "    over the data file to save memory.\n",
    "    TODO: can I delete this?\n",
    "\n",
    "    Args:\n",
    "        path (str): path to file\n",
    "\n",
    "    Returns:\n",
    "        List[str]: list of strings, where each string is a CoNNL-U record\n",
    "        for a sentence (one line per word, tab-separated fields)\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        data = f.read().strip()\n",
    "    data = data.split(\"\\n\\n\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'text': 'Bill',\n",
       "  'lemma': 'Bill',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 2,\n",
       "  'deprel': 'nsubj',\n",
       "  'start_char': 0,\n",
       "  'end_char': 4,\n",
       "  'ner': 'S-PERSON',\n",
       "  'multi_ner': ('S-PERSON',)},\n",
       " {'id': 2,\n",
       "  'text': 'seems',\n",
       "  'lemma': 'seem',\n",
       "  'upos': 'VERB',\n",
       "  'xpos': 'VBZ',\n",
       "  'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin',\n",
       "  'head': 0,\n",
       "  'deprel': 'root',\n",
       "  'start_char': 5,\n",
       "  'end_char': 10,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 3,\n",
       "  'text': 'honest',\n",
       "  'lemma': 'honest',\n",
       "  'upos': 'ADJ',\n",
       "  'xpos': 'JJ',\n",
       "  'feats': 'Degree=Pos',\n",
       "  'head': 2,\n",
       "  'deprel': 'xcomp',\n",
       "  'start_char': 11,\n",
       "  'end_char': 17,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll_u_parse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: 216kB [00:00, 95.3MB/s]                    \n",
      "2023-08-30 15:15:23 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-08-30 15:15:25 INFO: File exists: /Users/sally/stanza_resources/en/default.zip\n",
      "2023-08-30 15:15:29 INFO: Finished downloading models and saved to /Users/sally/stanza_resources.\n",
      "2023-08-30 15:15:29 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: 216kB [00:00, 85.5MB/s]                    \n",
      "2023-08-30 15:15:31 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-08-30 15:15:31 INFO: Using device: cpu\n",
      "2023-08-30 15:15:31 INFO: Loading: tokenize\n",
      "2023-08-30 15:15:31 INFO: Loading: pos\n",
      "2023-08-30 15:15:31 INFO: Loading: lemma\n",
      "2023-08-30 15:15:31 INFO: Loading: constituency\n",
      "2023-08-30 15:15:32 INFO: Loading: depparse\n",
      "2023-08-30 15:15:32 INFO: Loading: sentiment\n",
      "2023-08-30 15:15:32 INFO: Loading: ner\n",
      "2023-08-30 15:15:33 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'text': 'As', 'lemma': 'as', 'upos': 'ADP', 'xpos': 'IN', 'head': 3, 'deprel': 'case', 'start_char': 0, 'end_char': 2, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 2, 'text': 'a', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'feats': 'Definite=Ind|PronType=Art', 'head': 3, 'deprel': 'det', 'start_char': 3, 'end_char': 4, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 3, 'text': 'youth', 'lemma': 'youth', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': 5, 'deprel': 'obl', 'start_char': 5, 'end_char': 10, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 4, 'text': 'he', 'lemma': 'he', 'upos': 'PRON', 'xpos': 'PRP', 'feats': 'Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs', 'head': 5, 'deprel': 'nsubj', 'start_char': 11, 'end_char': 13, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 5, 'text': 'followed', 'lemma': 'follow', 'upos': 'VERB', 'xpos': 'VBD', 'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin', 'head': 0, 'deprel': 'root', 'start_char': 14, 'end_char': 22, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 6, 'text': 'a', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'feats': 'Definite=Ind|PronType=Art', 'head': 8, 'deprel': 'det', 'start_char': 23, 'end_char': 24, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 7, 'text': 'religious', 'lemma': 'religious', 'upos': 'ADJ', 'xpos': 'JJ', 'feats': 'Degree=Pos', 'head': 8, 'deprel': 'amod', 'start_char': 25, 'end_char': 34, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 8, 'text': 'pilgrimage', 'lemma': 'pilgrimage', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': 5, 'deprel': 'obj', 'start_char': 35, 'end_char': 45, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 9, 'text': 'that', 'lemma': 'that', 'upos': 'PRON', 'xpos': 'WDT', 'feats': 'PronType=Rel', 'head': 10, 'deprel': 'nsubj', 'start_char': 46, 'end_char': 50, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 10, 'text': 'took', 'lemma': 'take', 'upos': 'VERB', 'xpos': 'VBD', 'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin', 'head': 8, 'deprel': 'acl:relcl', 'start_char': 51, 'end_char': 55, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 11, 'text': 'him', 'lemma': 'he', 'upos': 'PRON', 'xpos': 'PRP', 'feats': 'Case=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs', 'head': 10, 'deprel': 'obj', 'start_char': 56, 'end_char': 59, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 12, 'text': 'to', 'lemma': 'to', 'upos': 'ADP', 'xpos': 'IN', 'head': 14, 'deprel': 'case', 'start_char': 60, 'end_char': 62, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 13, 'text': 'Transylvania', 'lemma': 'Transylvania', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': 14, 'deprel': 'compound', 'start_char': 63, 'end_char': 75, 'ner': 'B-ORG', 'multi_ner': ('B-ORG',)}, {'id': 14, 'text': 'College', 'lemma': 'College', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': 10, 'deprel': 'obl', 'start_char': 76, 'end_char': 83, 'ner': 'E-ORG', 'multi_ner': ('E-ORG',)}, {'id': 15, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 14, 'deprel': 'punct', 'start_char': 83, 'end_char': 84, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 16, 'text': 'a', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'feats': 'Definite=Ind|PronType=Art', 'head': 17, 'deprel': 'det', 'start_char': 85, 'end_char': 86, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 17, 'text': 'Disciples', 'lemma': 'Disciple', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Plur', 'head': 14, 'deprel': 'appos', 'start_char': 87, 'end_char': 96, 'ner': 'B-ORG', 'multi_ner': ('B-ORG',)}, {'id': 18, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 20, 'deprel': 'case', 'start_char': 97, 'end_char': 99, 'ner': 'I-ORG', 'multi_ner': ('I-ORG',)}, {'id': 19, 'text': 'Christ', 'lemma': 'Christ', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': 20, 'deprel': 'compound', 'start_char': 100, 'end_char': 106, 'ner': 'I-ORG', 'multi_ner': ('I-ORG',)}, {'id': 20, 'text': 'school', 'lemma': 'school', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': 17, 'deprel': 'nmod', 'start_char': 107, 'end_char': 113, 'ner': 'E-ORG', 'multi_ner': ('E-ORG',)}, {'id': 21, 'text': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 22, 'deprel': 'case', 'start_char': 114, 'end_char': 116, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 22, 'text': 'Lexington', 'lemma': 'Lexington', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': 14, 'deprel': 'nmod', 'start_char': 117, 'end_char': 126, 'ner': 'S-GPE', 'multi_ner': ('S-GPE',)}, {'id': 23, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 24, 'deprel': 'punct', 'start_char': 126, 'end_char': 127, 'ner': 'O', 'multi_ner': ('O',)}, {'id': 24, 'text': 'Kentucky', 'lemma': 'Kentucky', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': 22, 'deprel': 'appos', 'start_char': 128, 'end_char': 136, 'ner': 'S-GPE', 'multi_ner': ('S-GPE',)}, {'id': 25, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 5, 'deprel': 'punct', 'start_char': 136, 'end_char': 137, 'ner': 'O', 'multi_ner': ('O',)}]\n"
     ]
    }
   ],
   "source": [
    "# Define the sentence to parse\n",
    "sentence = \"As a youth he followed a religious pilgrimage that took him to Transylvania College, a Disciples of Christ school in Lexington, Kentucky.\"\n",
    "\n",
    "# Process the sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Access CoNLL-U format parse for the first sentence\n",
    "conll_u_parse = doc.sentences[0].to_dict()\n",
    "\n",
    "# Print the CoNLL-U format parse\n",
    "print(conll_u_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'text': 'As',\n",
       "  'lemma': 'as',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'IN',\n",
       "  'head': 3,\n",
       "  'deprel': 'case',\n",
       "  'start_char': 0,\n",
       "  'end_char': 2,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 2,\n",
       "  'text': 'a',\n",
       "  'lemma': 'a',\n",
       "  'upos': 'DET',\n",
       "  'xpos': 'DT',\n",
       "  'feats': 'Definite=Ind|PronType=Art',\n",
       "  'head': 3,\n",
       "  'deprel': 'det',\n",
       "  'start_char': 3,\n",
       "  'end_char': 4,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 3,\n",
       "  'text': 'youth',\n",
       "  'lemma': 'youth',\n",
       "  'upos': 'NOUN',\n",
       "  'xpos': 'NN',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'deprel': 'obl',\n",
       "  'start_char': 5,\n",
       "  'end_char': 10,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 4,\n",
       "  'text': 'he',\n",
       "  'lemma': 'he',\n",
       "  'upos': 'PRON',\n",
       "  'xpos': 'PRP',\n",
       "  'feats': 'Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 5,\n",
       "  'deprel': 'nsubj',\n",
       "  'start_char': 11,\n",
       "  'end_char': 13,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 5,\n",
       "  'text': 'followed',\n",
       "  'lemma': 'follow',\n",
       "  'upos': 'VERB',\n",
       "  'xpos': 'VBD',\n",
       "  'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin',\n",
       "  'head': 0,\n",
       "  'deprel': 'root',\n",
       "  'start_char': 14,\n",
       "  'end_char': 22,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 6,\n",
       "  'text': 'a',\n",
       "  'lemma': 'a',\n",
       "  'upos': 'DET',\n",
       "  'xpos': 'DT',\n",
       "  'feats': 'Definite=Ind|PronType=Art',\n",
       "  'head': 8,\n",
       "  'deprel': 'det',\n",
       "  'start_char': 23,\n",
       "  'end_char': 24,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 7,\n",
       "  'text': 'religious',\n",
       "  'lemma': 'religious',\n",
       "  'upos': 'ADJ',\n",
       "  'xpos': 'JJ',\n",
       "  'feats': 'Degree=Pos',\n",
       "  'head': 8,\n",
       "  'deprel': 'amod',\n",
       "  'start_char': 25,\n",
       "  'end_char': 34,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 8,\n",
       "  'text': 'pilgrimage',\n",
       "  'lemma': 'pilgrimage',\n",
       "  'upos': 'NOUN',\n",
       "  'xpos': 'NN',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'deprel': 'obj',\n",
       "  'start_char': 35,\n",
       "  'end_char': 45,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 9,\n",
       "  'text': 'that',\n",
       "  'lemma': 'that',\n",
       "  'upos': 'PRON',\n",
       "  'xpos': 'WDT',\n",
       "  'feats': 'PronType=Rel',\n",
       "  'head': 10,\n",
       "  'deprel': 'nsubj',\n",
       "  'start_char': 46,\n",
       "  'end_char': 50,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 10,\n",
       "  'text': 'took',\n",
       "  'lemma': 'take',\n",
       "  'upos': 'VERB',\n",
       "  'xpos': 'VBD',\n",
       "  'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin',\n",
       "  'head': 8,\n",
       "  'deprel': 'acl:relcl',\n",
       "  'start_char': 51,\n",
       "  'end_char': 55,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 11,\n",
       "  'text': 'him',\n",
       "  'lemma': 'he',\n",
       "  'upos': 'PRON',\n",
       "  'xpos': 'PRP',\n",
       "  'feats': 'Case=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 10,\n",
       "  'deprel': 'obj',\n",
       "  'start_char': 56,\n",
       "  'end_char': 59,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 12,\n",
       "  'text': 'to',\n",
       "  'lemma': 'to',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'IN',\n",
       "  'head': 14,\n",
       "  'deprel': 'case',\n",
       "  'start_char': 60,\n",
       "  'end_char': 62,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 13,\n",
       "  'text': 'Transylvania',\n",
       "  'lemma': 'Transylvania',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 14,\n",
       "  'deprel': 'compound',\n",
       "  'start_char': 63,\n",
       "  'end_char': 75,\n",
       "  'ner': 'B-ORG',\n",
       "  'multi_ner': ('B-ORG',)},\n",
       " {'id': 14,\n",
       "  'text': 'College',\n",
       "  'lemma': 'College',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 10,\n",
       "  'deprel': 'obl',\n",
       "  'start_char': 76,\n",
       "  'end_char': 83,\n",
       "  'ner': 'E-ORG',\n",
       "  'multi_ner': ('E-ORG',)},\n",
       " {'id': 15,\n",
       "  'text': ',',\n",
       "  'lemma': ',',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': ',',\n",
       "  'head': 14,\n",
       "  'deprel': 'punct',\n",
       "  'start_char': 83,\n",
       "  'end_char': 84,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 16,\n",
       "  'text': 'a',\n",
       "  'lemma': 'a',\n",
       "  'upos': 'DET',\n",
       "  'xpos': 'DT',\n",
       "  'feats': 'Definite=Ind|PronType=Art',\n",
       "  'head': 17,\n",
       "  'deprel': 'det',\n",
       "  'start_char': 85,\n",
       "  'end_char': 86,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 17,\n",
       "  'text': 'Disciples',\n",
       "  'lemma': 'Disciple',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Plur',\n",
       "  'head': 14,\n",
       "  'deprel': 'appos',\n",
       "  'start_char': 87,\n",
       "  'end_char': 96,\n",
       "  'ner': 'B-ORG',\n",
       "  'multi_ner': ('B-ORG',)},\n",
       " {'id': 18,\n",
       "  'text': 'of',\n",
       "  'lemma': 'of',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'IN',\n",
       "  'head': 20,\n",
       "  'deprel': 'case',\n",
       "  'start_char': 97,\n",
       "  'end_char': 99,\n",
       "  'ner': 'I-ORG',\n",
       "  'multi_ner': ('I-ORG',)},\n",
       " {'id': 19,\n",
       "  'text': 'Christ',\n",
       "  'lemma': 'Christ',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 20,\n",
       "  'deprel': 'compound',\n",
       "  'start_char': 100,\n",
       "  'end_char': 106,\n",
       "  'ner': 'I-ORG',\n",
       "  'multi_ner': ('I-ORG',)},\n",
       " {'id': 20,\n",
       "  'text': 'school',\n",
       "  'lemma': 'school',\n",
       "  'upos': 'NOUN',\n",
       "  'xpos': 'NN',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 17,\n",
       "  'deprel': 'nmod',\n",
       "  'start_char': 107,\n",
       "  'end_char': 113,\n",
       "  'ner': 'E-ORG',\n",
       "  'multi_ner': ('E-ORG',)},\n",
       " {'id': 21,\n",
       "  'text': 'in',\n",
       "  'lemma': 'in',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'IN',\n",
       "  'head': 22,\n",
       "  'deprel': 'case',\n",
       "  'start_char': 114,\n",
       "  'end_char': 116,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 22,\n",
       "  'text': 'Lexington',\n",
       "  'lemma': 'Lexington',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 14,\n",
       "  'deprel': 'nmod',\n",
       "  'start_char': 117,\n",
       "  'end_char': 126,\n",
       "  'ner': 'S-GPE',\n",
       "  'multi_ner': ('S-GPE',)},\n",
       " {'id': 23,\n",
       "  'text': ',',\n",
       "  'lemma': ',',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': ',',\n",
       "  'head': 24,\n",
       "  'deprel': 'punct',\n",
       "  'start_char': 126,\n",
       "  'end_char': 127,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)},\n",
       " {'id': 24,\n",
       "  'text': 'Kentucky',\n",
       "  'lemma': 'Kentucky',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 22,\n",
       "  'deprel': 'appos',\n",
       "  'start_char': 128,\n",
       "  'end_char': 136,\n",
       "  'ner': 'S-GPE',\n",
       "  'multi_ner': ('S-GPE',)},\n",
       " {'id': 25,\n",
       "  'text': '.',\n",
       "  'lemma': '.',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': '.',\n",
       "  'head': 5,\n",
       "  'deprel': 'punct',\n",
       "  'start_char': 136,\n",
       "  'end_char': 137,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',)}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll_u_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = copy.deepcopy(conll_u_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCoarse(x):\n",
    "    if \":\" in x:\n",
    "        return x[: x.index(\":\")]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_children(sentence):\n",
    "    \"\"\" Coarsify all the dependent relations, track all children \"\"\"\n",
    "    for line in sentence:\n",
    "        # make the dependency relation label coarse (ignore stuff after colon)\n",
    "        line[\"coarse_dep\"] = makeCoarse(line[\"deprel\"])\n",
    "\n",
    "        # identify the root, and skip to next word\n",
    "        if line[\"coarse_dep\"] == \"root\":\n",
    "            root = line[\"id\"]\n",
    "            continue\n",
    "\n",
    "        if line[\"coarse_dep\"].startswith(\"punct\"):\n",
    "            continue\n",
    "\n",
    "        headIndex = line[\"head\"] - 1\n",
    "        sentence[headIndex][\"children\"] = sentence[headIndex].get(\"children\", []) + [line[\"id\"]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'text': 'As',\n",
       "  'lemma': 'as',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'IN',\n",
       "  'head': 3,\n",
       "  'deprel': 'case',\n",
       "  'start_char': 0,\n",
       "  'end_char': 2,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'case'},\n",
       " {'id': 2,\n",
       "  'text': 'a',\n",
       "  'lemma': 'a',\n",
       "  'upos': 'DET',\n",
       "  'xpos': 'DT',\n",
       "  'feats': 'Definite=Ind|PronType=Art',\n",
       "  'head': 3,\n",
       "  'deprel': 'det',\n",
       "  'start_char': 3,\n",
       "  'end_char': 4,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'det'},\n",
       " {'id': 3,\n",
       "  'text': 'youth',\n",
       "  'lemma': 'youth',\n",
       "  'upos': 'NOUN',\n",
       "  'xpos': 'NN',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'deprel': 'obl',\n",
       "  'start_char': 5,\n",
       "  'end_char': 10,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'children': [1, 2, 1, 2],\n",
       "  'coarse_dep': 'obl'},\n",
       " {'id': 4,\n",
       "  'text': 'he',\n",
       "  'lemma': 'he',\n",
       "  'upos': 'PRON',\n",
       "  'xpos': 'PRP',\n",
       "  'feats': 'Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 5,\n",
       "  'deprel': 'nsubj',\n",
       "  'start_char': 11,\n",
       "  'end_char': 13,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'nsubj'},\n",
       " {'id': 5,\n",
       "  'text': 'followed',\n",
       "  'lemma': 'follow',\n",
       "  'upos': 'VERB',\n",
       "  'xpos': 'VBD',\n",
       "  'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin',\n",
       "  'head': 0,\n",
       "  'deprel': 'root',\n",
       "  'start_char': 14,\n",
       "  'end_char': 22,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'children': [3, 4, 3, 4, 8],\n",
       "  'coarse_dep': 'root'},\n",
       " {'id': 6,\n",
       "  'text': 'a',\n",
       "  'lemma': 'a',\n",
       "  'upos': 'DET',\n",
       "  'xpos': 'DT',\n",
       "  'feats': 'Definite=Ind|PronType=Art',\n",
       "  'head': 8,\n",
       "  'deprel': 'det',\n",
       "  'start_char': 23,\n",
       "  'end_char': 24,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'det'},\n",
       " {'id': 7,\n",
       "  'text': 'religious',\n",
       "  'lemma': 'religious',\n",
       "  'upos': 'ADJ',\n",
       "  'xpos': 'JJ',\n",
       "  'feats': 'Degree=Pos',\n",
       "  'head': 8,\n",
       "  'deprel': 'amod',\n",
       "  'start_char': 25,\n",
       "  'end_char': 34,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'amod'},\n",
       " {'id': 8,\n",
       "  'text': 'pilgrimage',\n",
       "  'lemma': 'pilgrimage',\n",
       "  'upos': 'NOUN',\n",
       "  'xpos': 'NN',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'deprel': 'obj',\n",
       "  'start_char': 35,\n",
       "  'end_char': 45,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'children': [6, 7, 10],\n",
       "  'coarse_dep': 'obj'},\n",
       " {'id': 9,\n",
       "  'text': 'that',\n",
       "  'lemma': 'that',\n",
       "  'upos': 'PRON',\n",
       "  'xpos': 'WDT',\n",
       "  'feats': 'PronType=Rel',\n",
       "  'head': 10,\n",
       "  'deprel': 'nsubj',\n",
       "  'start_char': 46,\n",
       "  'end_char': 50,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'nsubj'},\n",
       " {'id': 10,\n",
       "  'text': 'took',\n",
       "  'lemma': 'take',\n",
       "  'upos': 'VERB',\n",
       "  'xpos': 'VBD',\n",
       "  'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin',\n",
       "  'head': 8,\n",
       "  'deprel': 'acl:relcl',\n",
       "  'start_char': 51,\n",
       "  'end_char': 55,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'children': [9, 11, 14],\n",
       "  'coarse_dep': 'acl'},\n",
       " {'id': 11,\n",
       "  'text': 'him',\n",
       "  'lemma': 'he',\n",
       "  'upos': 'PRON',\n",
       "  'xpos': 'PRP',\n",
       "  'feats': 'Case=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 10,\n",
       "  'deprel': 'obj',\n",
       "  'start_char': 56,\n",
       "  'end_char': 59,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'obj'},\n",
       " {'id': 12,\n",
       "  'text': 'to',\n",
       "  'lemma': 'to',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'IN',\n",
       "  'head': 14,\n",
       "  'deprel': 'case',\n",
       "  'start_char': 60,\n",
       "  'end_char': 62,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'case'},\n",
       " {'id': 13,\n",
       "  'text': 'Transylvania',\n",
       "  'lemma': 'Transylvania',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 14,\n",
       "  'deprel': 'compound',\n",
       "  'start_char': 63,\n",
       "  'end_char': 75,\n",
       "  'ner': 'B-ORG',\n",
       "  'multi_ner': ('B-ORG',),\n",
       "  'coarse_dep': 'compound'},\n",
       " {'id': 14,\n",
       "  'text': 'College',\n",
       "  'lemma': 'College',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 10,\n",
       "  'deprel': 'obl',\n",
       "  'start_char': 76,\n",
       "  'end_char': 83,\n",
       "  'ner': 'E-ORG',\n",
       "  'multi_ner': ('E-ORG',),\n",
       "  'children': [12, 13, 17, 22],\n",
       "  'coarse_dep': 'obl'},\n",
       " {'id': 15,\n",
       "  'text': ',',\n",
       "  'lemma': ',',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': ',',\n",
       "  'head': 14,\n",
       "  'deprel': 'punct',\n",
       "  'start_char': 83,\n",
       "  'end_char': 84,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'punct'},\n",
       " {'id': 16,\n",
       "  'text': 'a',\n",
       "  'lemma': 'a',\n",
       "  'upos': 'DET',\n",
       "  'xpos': 'DT',\n",
       "  'feats': 'Definite=Ind|PronType=Art',\n",
       "  'head': 17,\n",
       "  'deprel': 'det',\n",
       "  'start_char': 85,\n",
       "  'end_char': 86,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'det'},\n",
       " {'id': 17,\n",
       "  'text': 'Disciples',\n",
       "  'lemma': 'Disciple',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Plur',\n",
       "  'head': 14,\n",
       "  'deprel': 'appos',\n",
       "  'start_char': 87,\n",
       "  'end_char': 96,\n",
       "  'ner': 'B-ORG',\n",
       "  'multi_ner': ('B-ORG',),\n",
       "  'children': [16, 20],\n",
       "  'coarse_dep': 'appos'},\n",
       " {'id': 18,\n",
       "  'text': 'of',\n",
       "  'lemma': 'of',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'IN',\n",
       "  'head': 20,\n",
       "  'deprel': 'case',\n",
       "  'start_char': 97,\n",
       "  'end_char': 99,\n",
       "  'ner': 'I-ORG',\n",
       "  'multi_ner': ('I-ORG',),\n",
       "  'coarse_dep': 'case'},\n",
       " {'id': 19,\n",
       "  'text': 'Christ',\n",
       "  'lemma': 'Christ',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 20,\n",
       "  'deprel': 'compound',\n",
       "  'start_char': 100,\n",
       "  'end_char': 106,\n",
       "  'ner': 'I-ORG',\n",
       "  'multi_ner': ('I-ORG',),\n",
       "  'coarse_dep': 'compound'},\n",
       " {'id': 20,\n",
       "  'text': 'school',\n",
       "  'lemma': 'school',\n",
       "  'upos': 'NOUN',\n",
       "  'xpos': 'NN',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 17,\n",
       "  'deprel': 'nmod',\n",
       "  'start_char': 107,\n",
       "  'end_char': 113,\n",
       "  'ner': 'E-ORG',\n",
       "  'multi_ner': ('E-ORG',),\n",
       "  'children': [18, 19],\n",
       "  'coarse_dep': 'nmod'},\n",
       " {'id': 21,\n",
       "  'text': 'in',\n",
       "  'lemma': 'in',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'IN',\n",
       "  'head': 22,\n",
       "  'deprel': 'case',\n",
       "  'start_char': 114,\n",
       "  'end_char': 116,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'case'},\n",
       " {'id': 22,\n",
       "  'text': 'Lexington',\n",
       "  'lemma': 'Lexington',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 14,\n",
       "  'deprel': 'nmod',\n",
       "  'start_char': 117,\n",
       "  'end_char': 126,\n",
       "  'ner': 'S-GPE',\n",
       "  'multi_ner': ('S-GPE',),\n",
       "  'children': [21, 24],\n",
       "  'coarse_dep': 'nmod'},\n",
       " {'id': 23,\n",
       "  'text': ',',\n",
       "  'lemma': ',',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': ',',\n",
       "  'head': 24,\n",
       "  'deprel': 'punct',\n",
       "  'start_char': 126,\n",
       "  'end_char': 127,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'punct'},\n",
       " {'id': 24,\n",
       "  'text': 'Kentucky',\n",
       "  'lemma': 'Kentucky',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': 22,\n",
       "  'deprel': 'appos',\n",
       "  'start_char': 128,\n",
       "  'end_char': 136,\n",
       "  'ner': 'S-GPE',\n",
       "  'multi_ner': ('S-GPE',),\n",
       "  'coarse_dep': 'appos'},\n",
       " {'id': 25,\n",
       "  'text': '.',\n",
       "  'lemma': '.',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': '.',\n",
       "  'head': 5,\n",
       "  'deprel': 'punct',\n",
       "  'start_char': 136,\n",
       "  'end_char': 137,\n",
       "  'ner': 'O',\n",
       "  'multi_ner': ('O',),\n",
       "  'coarse_dep': 'punct'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_children(sent)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 1,\n",
       "  'word': 'as',\n",
       "  'lemma': 'as',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 5,\n",
       "  'dep': 'obl',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'obl',\n",
       "  'children': [3]},\n",
       " {'index': 2,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 3,\n",
       "  'dep': 'det',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'det'},\n",
       " {'index': 3,\n",
       "  'word': 'youth',\n",
       "  'lemma': 'youth',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 1,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_',\n",
       "  'children': [2],\n",
       "  'coarse_dep': 'lifted_case'},\n",
       " {'index': 4,\n",
       "  'word': 'he',\n",
       "  'lemma': 'he',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'PERS-P3SG-NOM',\n",
       "  'morph': 'Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 5,\n",
       "  'dep': 'nsubj',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'nsubj'},\n",
       " {'index': 5,\n",
       "  'word': 'followed',\n",
       "  'lemma': 'follow',\n",
       "  'posUni': 'VERB',\n",
       "  'posFine': 'PAST',\n",
       "  'morph': 'Mood=Ind|Tense=Past|VerbForm=Fin',\n",
       "  'head': 0,\n",
       "  'dep': 'root',\n",
       "  '_': '_',\n",
       "  'children': [1, 4, 8, 17],\n",
       "  'coarse_dep': 'root'},\n",
       " {'index': 6,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 8,\n",
       "  'dep': 'det',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'det'},\n",
       " {'index': 7,\n",
       "  'word': 'religious',\n",
       "  'lemma': 'religious',\n",
       "  'posUni': 'ADJ',\n",
       "  'posFine': 'POS',\n",
       "  'morph': 'Degree=Pos',\n",
       "  'head': 8,\n",
       "  'dep': 'amod',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'amod'},\n",
       " {'index': 8,\n",
       "  'word': 'pilgrimage',\n",
       "  'lemma': 'pilgrimage',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'dep': 'obj',\n",
       "  '_': '_',\n",
       "  'children': [6, 7, 10],\n",
       "  'coarse_dep': 'obj'},\n",
       " {'index': 9,\n",
       "  'word': 'that',\n",
       "  'lemma': 'that',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'REL',\n",
       "  'morph': 'PronType=Rel',\n",
       "  'head': 10,\n",
       "  'dep': 'nsubj',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'nsubj'},\n",
       " {'index': 10,\n",
       "  'word': 'took',\n",
       "  'lemma': 'take',\n",
       "  'posUni': 'VERB',\n",
       "  'posFine': 'PAST',\n",
       "  'morph': 'Mood=Ind|Tense=Past|VerbForm=Fin',\n",
       "  'head': 8,\n",
       "  'dep': 'acl:relcl',\n",
       "  '_': '_',\n",
       "  'children': [9, 11, 12],\n",
       "  'coarse_dep': 'acl'},\n",
       " {'index': 11,\n",
       "  'word': 'him',\n",
       "  'lemma': 'he',\n",
       "  'posUni': 'PRON',\n",
       "  'posFine': 'PERS-P3SG-ACC',\n",
       "  'morph': 'Case=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs',\n",
       "  'head': 10,\n",
       "  'dep': 'obj',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'obj'},\n",
       " {'index': 12,\n",
       "  'word': 'to',\n",
       "  'lemma': 'to',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 10,\n",
       "  'dep': 'obl',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'obl',\n",
       "  'children': [13]},\n",
       " {'index': 13,\n",
       "  'word': 'transylvania',\n",
       "  'lemma': 'Transylvania',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 12,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'lifted_case',\n",
       "  'children': [14]},\n",
       " {'index': 14,\n",
       "  'word': 'college',\n",
       "  'lemma': 'College',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 13,\n",
       "  'dep': 'flat',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'flat'},\n",
       " {'index': 15,\n",
       "  'word': ',',\n",
       "  'lemma': ',',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Comma',\n",
       "  'morph': '_',\n",
       "  'head': 5,\n",
       "  'dep': 'punct',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'punct'},\n",
       " {'index': 16,\n",
       "  'word': 'a',\n",
       "  'lemma': 'a',\n",
       "  'posUni': 'DET',\n",
       "  'posFine': 'IND-SG',\n",
       "  'morph': 'Definite=Ind|PronType=Art',\n",
       "  'head': 17,\n",
       "  'dep': 'det',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'det'},\n",
       " {'index': 17,\n",
       "  'word': 'disciples',\n",
       "  'lemma': 'Disciple',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 5,\n",
       "  'dep': 'obj',\n",
       "  '_': '_',\n",
       "  'children': [16, 18],\n",
       "  'coarse_dep': 'obj'},\n",
       " {'index': 18,\n",
       "  'word': 'of',\n",
       "  'lemma': 'of',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 17,\n",
       "  'dep': 'nmod',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'nmod',\n",
       "  'children': [20]},\n",
       " {'index': 19,\n",
       "  'word': 'christ',\n",
       "  'lemma': 'Christ',\n",
       "  'posUni': 'ADJ',\n",
       "  'posFine': 'SPL',\n",
       "  'morph': 'Degree=Sup',\n",
       "  'head': 20,\n",
       "  'dep': 'amod',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'amod'},\n",
       " {'index': 20,\n",
       "  'word': 'school',\n",
       "  'lemma': 'school',\n",
       "  'posUni': 'NOUN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 18,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_',\n",
       "  'children': [19, 21],\n",
       "  'coarse_dep': 'lifted_case'},\n",
       " {'index': 21,\n",
       "  'word': 'in',\n",
       "  'lemma': 'in',\n",
       "  'posUni': 'ADP',\n",
       "  'posFine': '_',\n",
       "  'morph': '_',\n",
       "  'head': 20,\n",
       "  'dep': 'nmod',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'nmod',\n",
       "  'children': [22]},\n",
       " {'index': 22,\n",
       "  'word': 'lexington',\n",
       "  'lemma': 'Lexington',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 21,\n",
       "  'dep': 'lifted_case',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'lifted_case',\n",
       "  'children': [24]},\n",
       " {'index': 23,\n",
       "  'word': ',',\n",
       "  'lemma': ',',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Comma',\n",
       "  'morph': '_',\n",
       "  'head': 22,\n",
       "  'dep': 'punct',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'punct'},\n",
       " {'index': 24,\n",
       "  'word': 'kentucky',\n",
       "  'lemma': 'Kentucky',\n",
       "  'posUni': 'PROPN',\n",
       "  'posFine': 'SG-NOM',\n",
       "  'morph': 'Number=Sing',\n",
       "  'head': 22,\n",
       "  'dep': 'conj',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'conj'},\n",
       " {'index': 25,\n",
       "  'word': '.',\n",
       "  'lemma': '.',\n",
       "  'posUni': 'PUNCT',\n",
       "  'posFine': 'Period',\n",
       "  'morph': '_',\n",
       "  'head': 5,\n",
       "  'dep': 'punct',\n",
       "  '_': '_',\n",
       "  'coarse_dep': 'punct'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs_with_stack(graph, start_node):\n",
    "    stack = [start_node]\n",
    "    visited = set()\n",
    "\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        if node not in visited:\n",
    "            visited.add(node)\n",
    "            print(node)  # Process the node\n",
    "\n",
    "            for neighbor in graph[node]:\n",
    "                if neighbor not in visited:\n",
    "                    stack.append(neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_order(verb_idx, obj_idx, sentence, result):\n",
    "# Helper function for processing verb and object chunks\n",
    "    # verb_list = sentence[verb_idx]['children']\n",
    "    # obj_list = sentence[obj_idx]['children']\n",
    "    # verb_list = verb_list - obj_list\n",
    "    result[verb_idx], result[obj_idx] = sentence[obj_idx][\"id\"], sentence[verb_idx][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(sentence, root):\n",
    "# DFS for swaping verb and object\n",
    "# TODO: edge cases: 1. multiple obj\n",
    "#                   2. went to school happily -> to school went happily\n",
    "    result = [i for i in range(1, len(sentence) + 1)]\n",
    "    stack = [root]\n",
    "    visited = set()\n",
    "\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        if node not in visited:\n",
    "            visited.add(node)\n",
    "            print(node) # print out index of the node being processed\n",
    "\n",
    "            if not sentence[node-1].get(\"children\", None):\n",
    "                continue\n",
    "            for c in sentence[node-1][\"children\"]:\n",
    "                if sentence[node-1]['posUni'] == 'VERB' and sentence[c-1]['coarse_dep'] == 'obj':\n",
    "                    verb_idx, obj_idx = node - 1, c - 1\n",
    "                    swap_order(verb_idx, obj_idx, sentence, result)\n",
    "                if c not in visited:\n",
    "                    stack.append(c)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "17\n",
      "18\n",
      "20\n",
      "21\n",
      "22\n",
      "24\n",
      "19\n",
      "16\n",
      "8\n",
      "10\n",
      "12\n",
      "13\n",
      "14\n",
      "11\n",
      "9\n",
      "7\n",
      "6\n",
      "4\n",
      "1\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "res = swap(sent, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 17,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 11,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 5,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(sentence, node):\n",
    "    \"\"\"\n",
    "    sentence: list of dicts\n",
    "    node: the index of the current dependency tree node\n",
    "    \"\"\"\n",
    "    # node is the index in CoNLL-U format parses. Start with the root.\n",
    "    if not sentence[node-1][\"children\"]:\n",
    "        return\n",
    "    for c in sentence[node-1][\"children\"]:\n",
    "        swap(sentence, c)\n",
    "    if sentence[node-1]['posUni'] == 'VERB':\n",
    "        for c in sentence[node-1][\"children\"]:\n",
    "            if sentence[c-1]['coarse_dep'] == 'obj':\n",
    "                verb_idx, obj_idx = node-1, c-1\n",
    "                swap_order(verb_idx, obj_idx, sentence, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4028664378.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[48], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    sentence =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def swap_order(verb_idx, obj_idx, sentence, result):\n",
    "    verb_list = sentence[verb_idx]['children']\n",
    "    obj_list = sentence[obj_idx]['children']\n",
    "    # verb_list = verb_list - obj_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_order(verb_head, object_head):\n",
    "\tverb <- verb_head.get_constituent()\n",
    "\tobject <- object_head.get_constituent()\n",
    "\tVerb, object = object, verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(node):\n",
    "\t# The node is the root during first call\n",
    "    children <- node.get_all_children()\n",
    "    for c in children:\n",
    "        c <- swap(c)\n",
    "    # Find all verb/object pairs in children\n",
    "    verb <- find_verb(children)\n",
    "    if verb exists:\n",
    "        object <- find_object(children, verb)\n",
    "        if object exists:\n",
    "            node <- swap_order(verb, object)\n",
    "    return node\n",
    "\n",
    "def get_all_children():\n",
    "    # This one gets all direct children\n",
    "\n",
    "def swap_order(verb_head, object_head):\n",
    "\tverb <- verb_head.get_constituent()\n",
    "\tobject <- object_head.get_constituent()\n",
    "\tVerb, object = object, verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(node):\n",
    "    # Base case: If the node is a leaf, return it\n",
    "    if node.is_leaf():\n",
    "        return node\n",
    "\n",
    "    # Recursively swap verb/object pairs in children\n",
    "    for c in node.get_all_children():\n",
    "        c = swap(c)\n",
    "\n",
    "    # Find verb/object pairs in children\n",
    "    verb = find_verb(node.get_all_children())\n",
    "    if verb is not None:\n",
    "        obj = find_object(node.get_all_children(), verb)\n",
    "        if obj is not None:\n",
    "            node = swap_order(node, verb, obj)\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reversePair(sentence, model):\n",
    "    x, y = model[0], model[1]\n",
    "    # rev = False # only reverse it once\n",
    "    # moved = [None] * len(sentence)\n",
    "\n",
    "    for line in sentence:\n",
    "        key = line[\"coarse_dep\"]\n",
    "        if key == x:\n",
    "            x_idx = line[\"index\"] - 1\n",
    "        elif key == y:\n",
    "            y_idx = line[\"index\"] - 1\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    if x_idx and y_idx:\n",
    "        sentence[x_idx], sentence[y_idx] = sentence[y_idx], sentence[x_idx]\n",
    "\n",
    "        for line in sentence:\n",
    "            if line[\"head\"] == x_idx + 1:\n",
    "                line[\"reordered_head\"] = y_idx + 1\n",
    "            elif line[\"head\"] == y_idx + 1:\n",
    "                line[\"reordered_head\"] = x_idx + 1\n",
    "            else:\n",
    "                continue\n",
    "    return sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
