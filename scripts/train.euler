#!/bin/bash

#SBATCH -n 1
#SBATCH --cpus-per-task=16
#SBATCH --mem-per-cpu=16384
#SBATCH --gpus=rtx_3090:8
#SBATCH --gres=gpumem:11264m
#SBATCH --time=18:00:00
#SBATCH --open-mode=truncate
#SBATCH --mail-type=BEGIN,END,FAIL

#! Work directory (i.e. where the job will run):
workdir="$SLURM_SUBMIT_DIR"  # The value of SLURM_SUBMIT_DIR sets workdir to the directory
                             # in which sbatch is run (always run from root).
echo -e "$SLURM_SUBMIT_DIR.\n"
module purge
# module load eth_proxy gcc/8.2.0 python_gpu/3.9.9
module load eth_proxy stack/2024-04 gcc/8.5.0 python_cuda/3.9.18
source $workdir/env2/bin/activate


#! Run options for the application:
prefix=""
application="src/learn/train_model.sh"
options=""


cd $workdir
echo -e "Changed directory to `pwd`.\n"

echo -e "JobID: $SLURM_JOB_ID\n======"
echo "Time: `date`"
echo "Running on master node: `hostname`"
echo "Current directory: `pwd`"


CMD="$prefix $workdir/$application $options"
echo -e "\nExecuting command:\n==================\n$CMD\n"
eval $CMD
