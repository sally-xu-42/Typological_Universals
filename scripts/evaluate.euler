#!/bin/bash

#SBATCH -n 1
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16384
#SBATCH --gpus=4
#SBATCH --gres=gpumem:11264m
#SBATCH --time=23:00:00
#SBATCH --open-mode=truncate
#SBATCH --mail-type=END,FAIL


#! Model directory (i.e. where the model checkpoints are saved):
modeldir="/cluster/project/sachan/txu/Typological_Universal/checkpoints"

export WANDB_PROJECT="evaluation"
export WANDB__SERVICE_WAIT=300

#! Run options for the application:
case $TASK in

  blimp)
    workdir="/cluster/project/sachan/txu/evaluation-pipeline"
    prefix="python3"
    application="babylm_eval.py"
    options="$modeldir/${MODEL} ${MODEL_TYPE}"
    ;;

  blimp_checkpoints)
    workdir="/cluster/project/sachan/txu/Typological_Universal"

    for checkpoint in $workdir/checkpoints/${MODEL}/checkpoint-*; do
      if [ "$MODEL_TYPE" = decoder ]
      then
        echo -e "\nFixing tokenizer config for $checkpoint"
        python3 ./src/learn/fix_tokenizer.py --path $checkpoint
      fi

      CMD="${workdir}/scripts/evaluate.sh -t blimp -m ${checkpoint#*checkpoints/} -e ${MODEL_TYPE}"
      echo $CMD
      eval $CMD
      sleep 480
    done
    echo -e "\n"

    prefix=""
    application="echo"
    options="Started evaluation for each checkpoint of ${MODEL}"
    ;;

  glue)
    prefix=""
    application="finetune_all_tasks.sh"
    options="$workdir/models/${MODEL} 5e-5 10 32"
    ;;

  *)
    echo -n "unknown model name"
    ;;
esac


module purge
module load eth_proxy gcc/8.2.0 python_gpu/3.9.9
source $workdir/env2/bin/activate

echo -e "JobID: $SLURM_JOB_ID\n======"
echo "Time: `date`"
echo "Running on master node: `hostname`"
echo "Current directory: `pwd`"

cd $workdir
echo -e "Changed directory to `pwd`.\n"

CMD="$prefix $workdir/$application $options"
echo -e "\nExecuting command:\n==================\n$CMD\n"
eval $CMD
